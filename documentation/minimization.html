<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>minimization API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>minimization</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="minimization.minimize_scalar"><code class="name flex">
<span>def <span class="ident">minimize_scalar</span></span>(<span>f, xmin, xmax, xinit=None, method='goldenSearch', tol=1e-06, gtol=1e-06, maxIter=500, gf=None, constraints=[], penalityFactor=100, returnDict=False, storeIterValues=False, deriveMethod='finite-difference', dh=1e-09, stop_tolRatio=0.01, stop_gtolRatio=0.01, precallfunc=None)</span>
</code></dt>
<dd>
<div class="desc"><p>minimize_scalar : </p>
<p>Algorithmes de minimisation de fonctions scalaires à une variable.</p>
<p>Parameters : </p>
<pre><code>- f (callable) : une fonction scalaire d'une variable scalaire réelle.

- xmin (float) : borne inférieure du problème de minimisation.

- xmax (float) : borne supérieure du problème de minimisation.

- xinit (float or None) option : point initiale uniquement pour les méthodes [scalarGradient], si None xinit = (xmin+xmax)/2.

- method (str) option : méthode de minimisation. 
    *"goldenSearch" : méthode dichotomique basée sur le nombre d'or sans évaluation du gradient. 
    *"scalarGradient" : méthode du gradient appliqué en dimension scalaire. Gradient approché ou exacte.

- tol (float) option : tolérance sur critère d'arrêt. L'agorithme s'arrête si (residu &lt; tol)AND(gradient&lt;gtol).

- gtol (float) option : tolérance sur la valeur du gradient.

- maxIter (int) option : nombre limite d'itérations.

- gf (callable or None) : fonction de la dérivée. Fonction scalaire réelle. Si 'None' une approximation est utilisée.

- constraints (List of dict) option : 
        Definition des contraintes dans une liste de dictionnaires. Chaque dictionnaire contient les champs suivants 
            type : str
                Contraintes de type egalite 'eq' ou inegalite 'ineq' ; 
            fun : callable
                La fonction contrainte de la meme forme que func ; 
            jac : callable 
                Dérivée de la fonction contrainte de la même forme que gf ;

- penalityFactor (float) option : facteur de penalisation. La nouvelle fonction objectif est evaluee par la forme suivante :
                                            penal_objective_func = objective_func + sum(ci**2 if ci not feasible)*penalityFactor
                                            objectif_penalise = objectif + somme( ci**2 si ci non faisable)*facteur_penalite

- returnDict (bool) option : 
        Si l'option est True alors l'algorithme retourne un dictionnaire.

- storeIterValues (bool) option :
        L'évolution des variables durant la résolution est stockée dans un numpy array retourné dans le dictionnaire si returnDict = True ;

- deriveMethod (string) option : méthode d'approximation de la derivée. 
        *"finite-difference" : df = ( f(x+dh)-f(x) )/dh
        *"complex" : df = imag(f(x+1j*dh)/dh))

- dh (float) option : pas d'approximation de la dérivée. dh = max(abs(x)*dh,dh)

- stop_tolRatio (float) option : tolerance minimale pour forcer l'arrêt sur le résidu si le gradient n'atteint pas la tolerance gtol. 
        La tolerance minimale est calculée par mintol = tol*stop_tolRatio.

- stop_gtolRatio (float) option : tolerance minimale pour forcer l'arrêt sur le gradient si le résidu n'atteint pas la tolerance tol. 
        La tolerance minimale est calculée par mingtol = gtol*stop_gtolRatio.

- precallfunc (callable or None) option : 
        Definition d'une fonction sans renvoie de valeur à executer avant chaque evaluation de la fonction objectif, des gradients ou des contraintes.
</code></pre>
<p>Returns : </p>
<pre><code>Si (returnDict = False) : 
    x (float) : solution de l'algorithme d'optimisation.

Si (returnDict = False) : 
    dict :
        "method" : algorithme utilisé.
        "success" : True si l'agorithm a convergé correctement.
        "x": solution.
        "fmin": valeur de la fonction objectif.
        "residual": résidu.
        "gradResidual": résidu du gradient.
        "gradNorm": norme du gradient.
        "constrViolation": list des violations des contraintes. Vide si pas de contrainte.
        "iterations": nombre d'itérations.
        "functionCalls": nombre d'appels de la fonction.
        "gradientCalls": nombre d'appels du gradient.

        Si (storeIterValues = True) : 
            "xHistory" : array des variables de recherche. 
            "fHistory" : array des valeurs de la fonction objectif. 
            "rHistory" : array des valeurs du résidu.
</code></pre>
<p>Example : </p>
<pre><code>import numpy as np

xmin,xmax = 2.7,7.5
xinit = (xmax+xmin)/2

f = lambda x : np.sin(x)*x + np.sin(10/3*x)
df = lambda x : np.cos(x)*x + np.sin(x) + 10/3*np.cos(10/3*x)
x = np.linspace(xmin,xmax,250)
y = f(x)

dictgold = minimize_scalar(f,xmin,xmax,returnDict=True,method="goldenSearch")
dictgrad = minimize_scalar(f,xmin,xmax,xinit=xinit,returnDict=True,gf=df,method="scalarGradient")

Outputs : 
    #Solution goldenSearch
    method  :  goldenSearch
    success  :  True
    x  :  5.094751312571761
    fmin  :  -5.6832744082498365
    constrViolation  :  []
    residual  :  8.696778973964855e-07
    iterations  :  29
    functionCalls  :  32
    gradientCalls  :  0

    #Solution scalarGradient
    method  :  gradient
    success  :  True
    x  :  5.094751436644642
    fmin  :  -5.683274408249959
    residual  :  2.6531499293843317e-06
    gradResidual  :  1.8482260166763353e-09
    gradNorm  :  1.8482260166763353e-09
    constrViolation  :  []
    iterations  :  2
    functionCalls  :  7
    gradientCalls  :  3
</code></pre></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="minimization.continousBiObjective_NSGA"><code class="flex name class">
<span>class <span class="ident">continousBiObjective_NSGA</span></span>
<span>(</span><span>func1, func2, xmin, xmax, constraints=[], preprocess_function=None, func1_criterion='min', func2_criterion='min')</span>
</code></dt>
<dd>
<div class="desc"><p>continousBiObjective_NSGA : </p>
<p>Algorithme genetique d'optimisation bi-objectif à variables reelles.
Recherche du front de Pareto de fonctions scalaires à variables continues sur l'intervalle [xmin;xmax].</p>
<hr>
<p>Source : </p>
<p>A Fast and Elitist Multiobjective Genetic Algorithm : NSGA-II
Kalyanmoy Deb, Associate Member, IEEE, Amrit Pratap, Sameer Agarwal, and T. Meyarivan</p>
<p>Parameters : </p>
<pre><code>- func1 (callable) : 
    Fonction objectif a optimiser de la forme f(x) ou x est l'argument de la fonction de forme scalaire ou array et renvoie un scalaire ou array.

- func2 (callable) : 
    Fonction objectif a optimiser de la forme f(x) ou x est l'argument de la fonction de forme scalaire ou array et renvoie un scalaire ou array.

- xmin (array like) : 
    Borne inferieure des variables d'optimisation.

- xmax (array like) : 
    Borne supérieure des variables d'optimisation. Doit être de même dimension que xmin.

- constraints (List of dict) option : 
    Definition des contraintes dans une liste de dictionnaires. Chaque dictionnaire contient les champs suivants 
        type : str
            Contraintes de type egalite 'eq' ou inegalite 'ineq' ; 
        fun : callable
            La fonction contrainte de la meme forme que func ;

- preprocess_function (callable or None) option : 
    Definition d'une fonction sans renvoie de valeur à executer avant chaque evaluation de la fonction objectif func ou des contraintes.

- func1_criterion (string) option : 
    Definition du critere du premier objectif. 
      &gt;&gt;'min' = minimisation
      &gt;&gt;'max' = maximisation
      &gt;&gt; else : maximisation

- func2_criterion (string) option : 
    Definition du critere du deuxieme objectif. 
      &gt;&gt;'min' = minimisation
      &gt;&gt;'max' = maximisation
      &gt;&gt; else : maximisation
</code></pre>
<p>Example : </p>
<pre><code>import numpy as np

xmin,xmax = [-2],[2]
x = np.linspace(xmin[0],xmax[0],150)
f1 = lambda x : (0.5*x**2+x)/4
f2 = lambda x : (0.5*x**2-x)/4
c = lambda x : np.sin(x)
cons = [{"type":'ineq','fun':c}]

nsga_instance = continousBiObjective_NSGA(f1,
                                        f2,
                                        xmin,
                                        xmax,
                                        constraints=cons,
                                        func1_criterion='min',
                                        func2_criterion='min')

xfront,f1front,f2front = nsga_instance.optimize(20,100,verbose=False)
</code></pre></div>
<h3>Methods</h3>
<dl>
<dt id="minimization.continousBiObjective_NSGA.define_initial_population"><code class="name flex">
<span>def <span class="ident">define_initial_population</span></span>(<span>self, xstart)</span>
</code></dt>
<dd>
<div class="desc"><p>Definition d'une population initiale. </p>
<p>Parameter : </p>
<pre><code>- xstart (array(npop,ndof)) : 
    xstart est la solution initiale. Ses dimensions doivent etre de (npop,ndof). 
    npop la taille de la population et ndof le nombre de variable (degrees of freedom).
</code></pre></div>
</dd>
<dt id="minimization.continousBiObjective_NSGA.optimize"><code class="name flex">
<span>def <span class="ident">optimize</span></span>(<span>self, npop, ngen, nfront=None, verbose=False, returnDict=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Algorithme d'optimisation bi-objectifs sous contrainte. </p>
<p>Parameters : </p>
<pre><code>- npop (int) : 
    Taille de la population. Si npop est impair, l'algorithm l'augmente de 1. 
    Usuellement pour un probleme sans contrainte une population efficace est situee entre 5 et 20 fois le nombre de variable.
    Si les contraintes sont fortes, il sera utile d'augmenter la population.
    Ce parametre n'est pas pris en compte si une population initiale a ete definie.

- ngen (int) : 
    Nombre de generation. Usuellement une bonne pratique est de prendre 2 à 10 fois la taille de la population.

- nfront (int or None) option : 
    Nombre de point maximum dans le front de Pareto. Si None, alors nfront = 3*npop

- verbose (bool) option : 
    Affiche l'etat de la recherche pour chaque iteration. Peut ralentir l'execution.

- returnDict (bool) option : 
    Si l'option est True alors l'algorithme retourne un dictionnaire.
</code></pre>
<p>Returns : </p>
<pre><code>Si (returnDict = False) : 
    tuple : xsolutions, objective1_solutions, objective2_solutions (array(ndof,nfront), array(nfront), array(nfront))
        - xsolutions sont les solutions composants le front de Pareto.
        - objective1_solutions sont les points de la fonction 1 dans le front de Pareto. 
        - objective2_solutions sont les points de la fonction 2 dans le front de Pareto.

Si (returnDict = True) : 
    dict :
        "method" (str) : algorithm utilise.
        "optimization" (str) : minimisation ou maximisation.
        "success" (bool) : True si l'algorithm a converge, False sinon. 
        "x" (array or None) : solutions du front de Pareto.
        "f1" (array or None) : front de Pareto f1.
        "f2" (array or None) : front de Pareto f2.
</code></pre></div>
</dd>
<dt id="minimization.continousBiObjective_NSGA.redefine_constraints"><code class="name flex">
<span>def <span class="ident">redefine_constraints</span></span>(<span>self, constraints=[])</span>
</code></dt>
<dd>
<div class="desc"><p>Permet de redefinir les contraintes du probleme. </p>
<p>Parameter : </p>
<pre><code>- constraints (List of dict) option : 
        Definition des contraintes dans une liste de dictionnaires. Chaque dictionnaire contient les champs suivants 
            type : str
                Contraintes de type egalite 'eq' ou inegalite 'ineq' ; 
            fun : callable
                La fonction contrainte de la meme forme que func ;
</code></pre></div>
</dd>
<dt id="minimization.continousBiObjective_NSGA.redefine_objective"><code class="name flex">
<span>def <span class="ident">redefine_objective</span></span>(<span>self, func1, func2, func1_criterion='max', func2_criterion='max')</span>
</code></dt>
<dd>
<div class="desc"><p>Permet de redefinir les fonctions objectifs. </p>
<p>Parameters : </p>
<pre><code>- func1 (callable) : 
    Fonction objectif a optimiser de la forme f(x) ou x est l'argument de la fonction de forme scalaire ou array et renvoie un scalaire ou array.

- func2 (callable) : 
    Fonction objectif a optimiser de la forme f(x) ou x est l'argument de la fonction de forme scalaire ou array et renvoie un scalaire ou array.


- func1_criterion (string) option : 
    Definition du critere du premier objectif. 
      &gt;&gt;'min' = minimisation
      &gt;&gt;'max' = maximisation
      &gt;&gt; else : maximisation

- func2_criterion (string) option : 
    Definition du critere du deuxieme objectif. 
      &gt;&gt;'min' = minimisation
      &gt;&gt;'max' = maximisation
      &gt;&gt; else : maximisation
</code></pre></div>
</dd>
<dt id="minimization.continousBiObjective_NSGA.redefine_preprocess_func"><code class="name flex">
<span>def <span class="ident">redefine_preprocess_func</span></span>(<span>self, preprocess_function=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Permet de redefinir la fonction de preprocessing. </p>
<p>Parameter :</p>
<pre><code>- preprocess_function (callable or None) option : 
    Definition d'une fonction sans renvoie de valeur à executer avant chaque evaluation de la fonction objectif func ou des contraintes.
</code></pre></div>
</dd>
<dt id="minimization.continousBiObjective_NSGA.setConstraintMethod"><code class="name flex">
<span>def <span class="ident">setConstraintMethod</span></span>(<span>self, method='penality')</span>
</code></dt>
<dd>
<div class="desc"><p>Change la methode de prise en compte des contraintes. </p>
<p>Parameter : </p>
<pre><code>method (str) option : Definition de la methode de gestion des contraintes. 
    Si method = 'penality' utilisation d'une penalisation quadratique. 
    Si method = 'feasibility' les solutions non satisfaisante sont rejetees.
</code></pre></div>
</dd>
<dt id="minimization.continousBiObjective_NSGA.setCrossFactor"><code class="name flex">
<span>def <span class="ident">setCrossFactor</span></span>(<span>self, crossover_factor=1.25)</span>
</code></dt>
<dd>
<div class="desc"><p>Change la limite de barycentre dans l'operateur de reproduction. Si egale a 1, les enfants seront strictement entre les parents.
Si superieur a 1, les enfants peuvent etre a l'exterieur du segment parent. </p>
<p>Parameter : </p>
<pre><code>- crossover_factor (float) option : facteur de melange des individus parents ;
</code></pre></div>
</dd>
<dt id="minimization.continousBiObjective_NSGA.setMutationParameters"><code class="name flex">
<span>def <span class="ident">setMutationParameters</span></span>(<span>self, mutation_step=0.15, mutation_rate=0.25)</span>
</code></dt>
<dd>
<div class="desc"><p>Change les parametres de mutation. </p>
<p>Parameters : </p>
<pre><code>- mutation_step (float) option : limite de deplacement par mutation. Doit etre compris entre 0 et 1.

- mutation_rate (float) option : probabilite de mutation. Doit etre compris entre 0 et 1.
</code></pre></div>
</dd>
<dt id="minimization.continousBiObjective_NSGA.setPenalityParams"><code class="name flex">
<span>def <span class="ident">setPenalityParams</span></span>(<span>self, constraintAbsTol=0.001, penalityFactor=1000.0, penalityGrowth=1.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Change le parametrage de la penalisation de contrainte. </p>
<p>Parameters : </p>
<pre><code>- contraintAbsTol (float) option : tolerance des contraintes d'egalite. Si la contrainte i ||ci(xk)|| &lt;= contraintAbsTol, la solution est viable.

- penalityFactor (float) option : facteur de penalisation. La nouvelle fonction objectif est evaluee par la forme suivante :
                                        penal_objective_func = objective_func + sum(ci**2 if ci not feasible)*penalityFactor
                                        objectif_penalise = objectif + somme( ci**2 si ci non faisable)*facteur_penalite

- penalityGrowth (float) option : pour chaque iteration de l'algorithme le facteur de penalite peut croitre d'un facteur penalityGrowth
                                        penalityFactor_(k+1) = penalityFactor_(k)*penalityGrowth
</code></pre></div>
</dd>
<dt id="minimization.continousBiObjective_NSGA.setPreSelectNumber"><code class="name flex">
<span>def <span class="ident">setPreSelectNumber</span></span>(<span>self, nbr_preselected=2)</span>
</code></dt>
<dd>
<div class="desc"><p>Change le nombre d'individus pre-selectionnes dans un mode de selection par tournois. </p>
<p>Parameter : </p>
<pre><code>- nbr_preselected (int) option : nombre d'individus participants à chaque tournois. Superieur a 1.
</code></pre></div>
</dd>
<dt id="minimization.continousBiObjective_NSGA.setSelectionMethod"><code class="name flex">
<span>def <span class="ident">setSelectionMethod</span></span>(<span>self, method='tournament')</span>
</code></dt>
<dd>
<div class="desc"><p>Change la methode de selection. </p>
<p>Parameter : </p>
<pre><code>- method (str) option : Definition de la methode de selection. 
    Si method = 'tournament' : selection par tournois.
</code></pre></div>
</dd>
<dt id="minimization.continousBiObjective_NSGA.setSharingDist"><code class="name flex">
<span>def <span class="ident">setSharingDist</span></span>(<span>self, sharingDist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Change le rayon de diversite des solutions.</p>
<p>Parameter : </p>
<pre><code>- sharingDict (float or None) option : Rayon de diversite de solution. Si None, le parametre est initialise a 1/(taille population).
</code></pre></div>
</dd>
</dl>
</dd>
<dt id="minimization.continousSingleObjectiveGA"><code class="flex name class">
<span>class <span class="ident">continousSingleObjectiveGA</span></span>
<span>(</span><span>func, xmin, xmax, constraints=[], preprocess_function=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Instance de continousSingleObjectiveGA : </p>
<p>Algorithme genetique d'optimisation de fonction mono-objectif à variables reelles
Recherche d'un optimum global de la fonction f sur les bornes xmin-xmax. </p>
<p>Parameters : </p>
<pre><code>- func (callable) : 
    Fonction objectif a optimiser de la forme f(x) ou x est l'argument de la fonction de forme scalaire ou array et renvoie un scalaire ou array.

- xmin (array like) : 
    Borne inferieure des variables d'optimisation.

- xmax (array like) : 
    Borne supérieure des variables d'optimisation. Doit être de même dimension que xmin.

- constraints (List of dict) option : 
    Definition des contraintes dans une liste de dictionnaires. Chaque dictionnaire contient les champs suivants 
        type : str
            Contraintes de type egalite 'eq' ou inegalite 'ineq' ; 
        fun : callable
            La fonction contrainte de la meme forme que func ;

- preprocess_function (callable or None) option : 
    Definition d'une fonction sans renvoie de valeur à executer avant chaque evaluation de la fonction objectif func ou des contraintes.
</code></pre>
<p>Example : </p>
<pre><code>func = lambda x : x[0]**2 + x[1]**2
xmin = [-1,-1]
xmax = [1,1]
ga_instance = continousSingleObjectiveGA(func,
                                        xmin,
                                        xmax)


resGA = ga_instance.minimize(20,100,verbose=False,returnDict=True)

Ouputs : 
    ############################################################

    AG iterations completed     
    Success :  True
    Number of generations :  100
    Population size :  20
    Elapsed time : 0.162 s
    ############################################################

    resGA = {
        method  :  Continous Single Objective Genetic Algorithm
        optimization  :  minimization
        success  :  True
        x  :  [-0.00222156  0.00380852] #may vary
        f  :  1.9440156259914855e-05    #may vary
        constrViolation  :  []
        }
</code></pre></div>
<h3>Methods</h3>
<dl>
<dt id="minimization.continousSingleObjectiveGA.define_initial_population"><code class="name flex">
<span>def <span class="ident">define_initial_population</span></span>(<span>self, xstart)</span>
</code></dt>
<dd>
<div class="desc"><p>Definition d'une population initiale. </p>
<p>Parameter : </p>
<pre><code>- xstart (array(npop,ndof)) : 
    xstart est la solution initiale. Ses dimensions doivent etre de (npop,ndof). 
    npop la taille de la population et ndof le nombre de variable (degrees of freedom).
</code></pre></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.getLastPopulation"><code class="name flex">
<span>def <span class="ident">getLastPopulation</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.getStatOptimisation"><code class="name flex">
<span>def <span class="ident">getStatOptimisation</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.maximize"><code class="name flex">
<span>def <span class="ident">maximize</span></span>(<span>self, npop, ngen, verbose=True, returnDict=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Algorithme de maximisation de la fonction objectif sous contrainte. </p>
<p>Parameters : </p>
<pre><code>- npop (int) : 
    Taille de la population. Si npop est impair, l'algorithm l'augmente de 1. 
    Usuellement pour un probleme sans contrainte une population efficace est situee entre 5 et 20 fois le nombre de variable.
    Si les contraintes sont fortes, il sera utile d'augmenter la population.
    Ce parametre n'est pas pris en compte si une population initiale a ete definie.

- ngen (int) : 
    Nombre de generation. Usuellement une bonne pratique est de prendre 2 à 10 fois la taille de la population.

- verbose (bool) option : 
    Affiche l'etat de la recherche pour chaque iteration. Peut ralentir l'execution.

- returnDict (bool) option : 
    Si l'option est True alors l'algorithme retourne un dictionnaire.
</code></pre>
<p>Returns : </p>
<pre><code>Si (returnDict = False) : 
    tuple : xsolution, objective_solution (array(ndof), array(1)) ou (None, None)
        - xsolution est la meilleure solution x historisee. Sa dimension correspond a ndof, la taille du probleme initial.
        - objective_solution est la fonction objectif evaluee à xsolution. 
        Si la solution n'a pas convergee et les contraintes jamais validee, l'algorithme return (None, None)

Si (returnDict = False) : 
    dict :
        "method" (str) : algorithm utilise.
        "optimization" (str) : minimisation ou maximisation.
        "success" (bool) : True si l'algorithm a converge, False sinon. 
        "x" (array or None) : meilleure solution ou None si success = False.
        "f" (array or None) : meilleure objectif ou None si success = False. 
        "constrViolation" (List of float) : violation des contraintes. Liste vide si aucune contrainte.
</code></pre></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.minimize"><code class="name flex">
<span>def <span class="ident">minimize</span></span>(<span>self, npop, ngen, verbose=True, returnDict=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Algorithme de minimisation de la fonction objectif sous contrainte.</p>
<p>Parameters : </p>
<pre><code>- npop (int) : 
    Taille de la population. Si npop est impair, l'algorithm l'augmente de 1. 
    Usuellement pour un probleme sans contrainte une population efficace est situee entre 5 et 20 fois le nombre de variable.
    Si les contraintes sont fortes, il sera utile d'augmenter la population.
    Ce parametre n'est pas pris en compte si une population initiale a ete definie.

- ngen (int) : 
    Nombre de generation. Usuellement une bonne pratique est de prendre 2 à 10 fois la taille de la population.

- verbose (bool) option : 
    Affiche l'etat de la recherche pour chaque iteration. Peut ralentir l'execution.

- returnDict (bool) option : 
    Si l'option est True alors l'algorithme retourne un dictionnaire.
</code></pre>
<p>Returns : </p>
<pre><code>Si (returnDict = False) : 
    tuple : xsolution, objective_solution (array(ndof), array(1)) ou (None, None)
        - xsolution est la meilleure solution x historisee. Sa dimension correspond a ndof, la taille du probleme initial.
        - objective_solution est la fonction objectif evaluee à xsolution. 
        Si la solution n'a pas convergee et les contraintes jamais validee, l'algorithme return (None, None)

Si (returnDict = False) : 
    dict :
        "method" (str) : algorithm utilise.
        "optimization" (str) : minimisation ou maximisation.
        "success" (bool) : True si l'algorithm a converge, False sinon. 
        "x" (array or None) : meilleure solution ou None si success = False.
        "f" (array or None) : meilleure objectif ou None si success = False. 
        "constrViolation" (List of float) : violation des contraintes. Liste vide si aucune contrainte.
</code></pre></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.redefine_constraints"><code class="name flex">
<span>def <span class="ident">redefine_constraints</span></span>(<span>self, constraints=[])</span>
</code></dt>
<dd>
<div class="desc"><p>Permet de redefinir les contraintes du probleme. </p>
<p>Parameter : </p>
<pre><code>- constraints (List of dict) option : 
        Definition des contraintes dans une liste de dictionnaires. Chaque dictionnaire contient les champs suivants 
            type : str
                Contraintes de type egalite 'eq' ou inegalite 'ineq' ; 
            fun : callable
                La fonction contrainte de la meme forme que func ;
</code></pre></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.redefine_objective"><code class="name flex">
<span>def <span class="ident">redefine_objective</span></span>(<span>self, func)</span>
</code></dt>
<dd>
<div class="desc"><p>Permet de redefinir la fonction objectif. </p>
<p>Parameter : </p>
<pre><code>- func (callable) : 
    Fonction objectif a optimiser de la forme f(x) ou x est l'argument de la fonction de forme scalaire ou array et renvoie un scalaire ou array.
</code></pre></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.redefine_preprocess_func"><code class="name flex">
<span>def <span class="ident">redefine_preprocess_func</span></span>(<span>self, preprocess_function=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Permet de redefinir la fonction de preprocessing. </p>
<p>Parameter</p>
<pre><code>- preprocess_function (callable or None) option : 
    Definition d'une fonction sans renvoie de valeur à executer avant chaque evaluation de la fonction objectif func ou des contraintes.
</code></pre></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.setConstraintMethod"><code class="name flex">
<span>def <span class="ident">setConstraintMethod</span></span>(<span>self, method='penality')</span>
</code></dt>
<dd>
<div class="desc"><p>Change la methode de prise en compte des contraintes. </p>
<p>Parameter : </p>
<pre><code>method (str) option : Definition de la methode de gestion des contraintes. 
    Si method = 'penality' utilisation d'une penalisation quadratique. 
    Si method = 'feasibility' les solutions non satisfaisante sont rejetees.
</code></pre></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.setCrossFactor"><code class="name flex">
<span>def <span class="ident">setCrossFactor</span></span>(<span>self, crossover_factor=1.25)</span>
</code></dt>
<dd>
<div class="desc"><p>Change la limite de barycentre dans l'operateur de reproduction. Si egale a 1, les enfants seront strictement entre les parents.
Si superieur a 1, les enfants peuvent etre a l'exterieur du segment parent. </p>
<p>Parameter : </p>
<pre><code>- crossover_factor (float) option : facteur de melange des individus parents ;
</code></pre></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.setElitisme"><code class="name flex">
<span>def <span class="ident">setElitisme</span></span>(<span>self, elitisme=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Booleen d'activation d'un operateur d'elitsime herite de la methode NSGA-II.
L'elitisme melange les populations parents et enfants pour en extraire les meilleurs individus.
Si cette option est desactivee, la methode de contrainte par faisabilite est impossible. L'algorithme utilisera une penalite.</p>
<p>Parameter : </p>
<pre><code>- elitisme (bool) option : actif (True) ou inactif (False)
</code></pre></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.setMutationParameters"><code class="name flex">
<span>def <span class="ident">setMutationParameters</span></span>(<span>self, mutation_step=0.15, mutation_rate=0.25)</span>
</code></dt>
<dd>
<div class="desc"><p>Change les parametres de mutation. </p>
<p>Parameters : </p>
<pre><code>- mutation_step (float) option : limite de deplacement par mutation. Doit etre compris entre 0 et 1.

- mutation_rate (float) option : probabilite de mutation. Doit etre compris entre 0 et 1.
</code></pre></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.setPenalityParams"><code class="name flex">
<span>def <span class="ident">setPenalityParams</span></span>(<span>self, constraintAbsTol=0.001, penalityFactor=1000.0, penalityGrowth=1.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Change le parametrage de la penalisation de contrainte. </p>
<p>Parameters : </p>
<pre><code>- contraintAbsTol (float) option : tolerance des contraintes d'egalite. Si la contrainte i ||ci(xk)|| &lt;= contraintAbsTol, la solution est viable.

- penalityFactor (float) option : facteur de penalisation. La nouvelle fonction objectif est evaluee par la forme suivante :
                                        penal_objective_func = objective_func + sum(ci**2 if ci not feasible)*penalityFactor
                                        objectif_penalise = objectif + somme( ci**2 si ci non faisable)*facteur_penalite

- penalityGrowth (float) option : pour chaque iteration de l'algorithme le facteur de penalite peut croitre d'un facteur penalityGrowth
                                        penalityFactor_(k+1) = penalityFactor_(k)*penalityGrowth
</code></pre></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.setPreSelectNumber"><code class="name flex">
<span>def <span class="ident">setPreSelectNumber</span></span>(<span>self, nbr_preselected=2)</span>
</code></dt>
<dd>
<div class="desc"><p>Change le nombre d'individus pre-selectionnes dans un mode de selection par tournois. </p>
<p>Parameter : </p>
<pre><code>- nbr_preselected (int) option : nombre d'individus participants à chaque tournois. Superieur a 1.
</code></pre></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.setSelectionMethod"><code class="name flex">
<span>def <span class="ident">setSelectionMethod</span></span>(<span>self, method='tournament')</span>
</code></dt>
<dd>
<div class="desc"><p>Change la methode de selection. </p>
<p>Parameter : </p>
<pre><code>- method (str) option : Definition de la methode de selection. 
    Si method = 'tournament' : selection par tournois. 
    Si method = 'SRWRS' : selection par "Stochastic remainder without replacement selection" [Golberg]
</code></pre>
<p>[Golberg]
D.E Goldberg. Genetic Algorithms in Search, Optimization and Machine Learning. Reading MA Addison Wesley, 1989.</p></div>
</dd>
<dt id="minimization.continousSingleObjectiveGA.setSharingDist"><code class="name flex">
<span>def <span class="ident">setSharingDist</span></span>(<span>self, sharingDist=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Change le rayon de diversite des solutions.</p>
<p>Parameter : </p>
<pre><code>- sharingDict (float or None) option : Rayon de diversite de solution. Si None, le parametre est initialise a 1/(taille population).
</code></pre></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="minimization.minimize_scalar" href="#minimization.minimize_scalar">minimize_scalar</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="minimization.continousBiObjective_NSGA" href="#minimization.continousBiObjective_NSGA">continousBiObjective_NSGA</a></code></h4>
<ul class="">
<li><code><a title="minimization.continousBiObjective_NSGA.define_initial_population" href="#minimization.continousBiObjective_NSGA.define_initial_population">define_initial_population</a></code></li>
<li><code><a title="minimization.continousBiObjective_NSGA.optimize" href="#minimization.continousBiObjective_NSGA.optimize">optimize</a></code></li>
<li><code><a title="minimization.continousBiObjective_NSGA.redefine_constraints" href="#minimization.continousBiObjective_NSGA.redefine_constraints">redefine_constraints</a></code></li>
<li><code><a title="minimization.continousBiObjective_NSGA.redefine_objective" href="#minimization.continousBiObjective_NSGA.redefine_objective">redefine_objective</a></code></li>
<li><code><a title="minimization.continousBiObjective_NSGA.redefine_preprocess_func" href="#minimization.continousBiObjective_NSGA.redefine_preprocess_func">redefine_preprocess_func</a></code></li>
<li><code><a title="minimization.continousBiObjective_NSGA.setConstraintMethod" href="#minimization.continousBiObjective_NSGA.setConstraintMethod">setConstraintMethod</a></code></li>
<li><code><a title="minimization.continousBiObjective_NSGA.setCrossFactor" href="#minimization.continousBiObjective_NSGA.setCrossFactor">setCrossFactor</a></code></li>
<li><code><a title="minimization.continousBiObjective_NSGA.setMutationParameters" href="#minimization.continousBiObjective_NSGA.setMutationParameters">setMutationParameters</a></code></li>
<li><code><a title="minimization.continousBiObjective_NSGA.setPenalityParams" href="#minimization.continousBiObjective_NSGA.setPenalityParams">setPenalityParams</a></code></li>
<li><code><a title="minimization.continousBiObjective_NSGA.setPreSelectNumber" href="#minimization.continousBiObjective_NSGA.setPreSelectNumber">setPreSelectNumber</a></code></li>
<li><code><a title="minimization.continousBiObjective_NSGA.setSelectionMethod" href="#minimization.continousBiObjective_NSGA.setSelectionMethod">setSelectionMethod</a></code></li>
<li><code><a title="minimization.continousBiObjective_NSGA.setSharingDist" href="#minimization.continousBiObjective_NSGA.setSharingDist">setSharingDist</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="minimization.continousSingleObjectiveGA" href="#minimization.continousSingleObjectiveGA">continousSingleObjectiveGA</a></code></h4>
<ul class="">
<li><code><a title="minimization.continousSingleObjectiveGA.define_initial_population" href="#minimization.continousSingleObjectiveGA.define_initial_population">define_initial_population</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.getLastPopulation" href="#minimization.continousSingleObjectiveGA.getLastPopulation">getLastPopulation</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.getStatOptimisation" href="#minimization.continousSingleObjectiveGA.getStatOptimisation">getStatOptimisation</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.maximize" href="#minimization.continousSingleObjectiveGA.maximize">maximize</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.minimize" href="#minimization.continousSingleObjectiveGA.minimize">minimize</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.redefine_constraints" href="#minimization.continousSingleObjectiveGA.redefine_constraints">redefine_constraints</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.redefine_objective" href="#minimization.continousSingleObjectiveGA.redefine_objective">redefine_objective</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.redefine_preprocess_func" href="#minimization.continousSingleObjectiveGA.redefine_preprocess_func">redefine_preprocess_func</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.setConstraintMethod" href="#minimization.continousSingleObjectiveGA.setConstraintMethod">setConstraintMethod</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.setCrossFactor" href="#minimization.continousSingleObjectiveGA.setCrossFactor">setCrossFactor</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.setElitisme" href="#minimization.continousSingleObjectiveGA.setElitisme">setElitisme</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.setMutationParameters" href="#minimization.continousSingleObjectiveGA.setMutationParameters">setMutationParameters</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.setPenalityParams" href="#minimization.continousSingleObjectiveGA.setPenalityParams">setPenalityParams</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.setPreSelectNumber" href="#minimization.continousSingleObjectiveGA.setPreSelectNumber">setPreSelectNumber</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.setSelectionMethod" href="#minimization.continousSingleObjectiveGA.setSelectionMethod">setSelectionMethod</a></code></li>
<li><code><a title="minimization.continousSingleObjectiveGA.setSharingDist" href="#minimization.continousSingleObjectiveGA.setSharingDist">setSharingDist</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>